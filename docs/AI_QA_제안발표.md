# 제안발표 AI 영역 예상 Q&A (20문)

> 아산병원 통합 데이터 플랫폼 구축 제안발표 — AI 부분 질의응답 대비

---

## Q1. 비정형 Processing에서 NLP/NER 구조화는 어떤 모델을 사용하나요?

**A:** BioClinicalBERT(`d4data/biomedical-ner-all`) 기반의 의료 특화 NER 모델을 사용합니다. 영문 의료 텍스트는 BioClinicalBERT 토큰 분류로 처리하고, 한글 텍스트는 67개 의학 용어 사전 + 정규식 패턴 매칭으로 처리합니다. 추출된 엔티티는 rapidfuzz CodeMapper(85% 임계값)를 통해 SNOMED CT, ICD-10, LOINC, RxNorm 등 표준 코드에 자동 매핑되며, 최종적으로 OMOP CDM `note_nlp` 테이블에 적재됩니다. GPU 서버에서 추론하며 약 287MB VRAM만 사용하여 경량입니다.

---

## Q2. DICOM 영상 파싱은 어떤 메타데이터를 추출하나요?

**A:** `pydicom` 라이브러리로 DICOM 헤더에서 PatientID, StudyDate, Modality(CT/MRI/X-ray 등), BodyPartExamined, StudyDescription, SeriesDescription, 이미지 해상도(Rows/Columns), BitsAllocated, Manufacturer, InstitutionName 등 12개 핵심 필드를 추출합니다. 원본 DICOM 파일은 MinIO S3 오브젝트 스토리지에 보관하고, 추출된 메타데이터는 OMOP CDM `imaging_study` 테이블에 JSONB 형태로 적재하여 검색/분석이 가능합니다.

---

## Q3. Text2SQL(자연어→SQL) 파이프라인의 정확도는 어떻게 보장하나요?

**A:** 메타스트림이 수집한 IT메타를 기반으로 비즈메타를 자동 생성하고, 이를 활용해 정확도를 확보합니다. 시연에서 보셨듯이 "폐렴 소견 흉부 X-ray 보여줘"라고 자연어로 질의하면 다음 과정이 진행됩니다:

1. **IT메타 수집** — 메타스트림이 OMOP CDM 18개 테이블의 컬럼, 타입, 관계 등 IT메타를 자동 수집
2. **비즈메타 자동 생성** — IT메타를 바탕으로 LLM이 업무 용어, 유사어, 테이블 설명 등 비즈메타를 생성 (사고 과정에서 확인 가능)
3. **자연어→SQL 변환** — 비즈메타가 컨텍스트로 주입되어, 사용자가 테이블 구조를 몰라도 자연어만으로 정확한 SQL 생성
4. **검증** — 문법 검증 + 존재하지 않는 테이블/컬럼 참조 차단
5. **멀티턴 연속 질의** — 이전 대화를 기억하여 "남성 환자의 평균 나이는?" 같은 후속 질의도 문맥을 이어받아 처리

비즈메타가 핵심입니다. 비즈메타가 있기 때문에 연구자가 물리 테이블명이나 컬럼명을 몰라도 업무 용어로 데이터에 접근할 수 있고, AI의 사고 과정도 투명하게 확인할 수 있습니다. 추가로 SELECT만 허용(읽기 전용)하고, DROP/DELETE/UPDATE 등 위험 SQL은 AI Safety 레이어에서 원천 차단합니다.

---

## Q4. LLM은 왜 오픈소스 모델을 선택했나요? GPT-4나 Claude를 쓰면 안 되나요?

**A:** 의료 데이터의 특성상 **원내 폐쇄망 운영**이 원칙입니다. 환자 데이터가 포함된 질의가 외부 API로 전송되면 개인정보보호법 및 의료법 위반 소지가 있습니다. 따라서 GPU 서버에 직접 배포 가능한 오픈소스 모델(Qwen3-32B-AWQ, XiYanSQL-7B)을 선택했습니다. 다만, 비식별화된 메타데이터 분석 등 개인정보가 포함되지 않는 작업에는 Claude/Gemini API를 폴백으로 사용할 수 있도록 멀티 프로바이더 아키텍처를 설계했습니다.

---

## Q5. 임상노트 구조화 파이프라인의 처리 흐름을 설명해주세요.

**A:** 다음 순서로 처리됩니다:
1. 임상노트 텍스트 입력 (경과기록, 병리보고서, 영상소견 등)
2. 원본 텍스트를 MinIO S3에 저장 (원본 보존)
3. **LLM 섹션 분리** — 주소/현병력/소견/평가/계획 5개 섹션으로 자동 분리
4. **BioClinicalBERT NER** — 진단, 약물, 검사, 시술 엔티티 추출 + 표준코드 매핑
5. **OMOP CDM 적재** — `note` 테이블에 원문, `note_nlp` 테이블에 각 엔티티를 행 단위로 적재
6. 작업 이력을 `unstructured_job` 테이블에 기록

실제 테스트에서 임상노트 1건 처리에 약 10초 소요되며, 엔티티당 SNOMED CT/ICD-10/LOINC/RxNorm 매핑 정확도 95% 이상을 확인했습니다.

---

## Q6. RAG(검색증강생성) 파이프라인은 어떻게 구성되어 있나요?

**A:** Milvus 벡터 DB(v2.4.0) 기반입니다. `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` 모델로 384차원 임베딩을 생성하고, IVF_FLAT 인덱스(COSINE 유사도, nlist=128)로 검색합니다. OMOP CDM 메타데이터(테이블 설명, 컬럼 설명, 비즈메타)를 벡터화하여 저장하고, 사용자 질문이 들어오면 유사한 스키마 컨텍스트를 검색하여 LLM 프롬프트에 주입합니다. 이를 통해 LLM이 실제 DB 구조를 정확히 파악한 상태에서 SQL을 생성할 수 있습니다.

---

## Q7. AI 안전성(Safety)은 어떻게 보장하나요?

**A:** 3중 방어 체계를 구축했습니다:
1. **입력 단계** — 프롬프트 인젝션 탐지 (34개 패턴, 가중 점수제, 70점 초과 시 차단)
2. **처리 단계** — PII 탐지 및 마스킹 (주민등록번호, 전화번호, 이메일 등 자동 필터링)
3. **출력 단계** — 응답 검증 (SQL 환각 탐지, 유해 SQL 차단, PII 유출 방지, 응답 길이 검증)

모든 AI 요청/응답은 감사 로그(`ai_safety_log`)에 기록되며, CSV 내보내기가 가능하여 규정 준수 감사에 활용할 수 있습니다.

---

## Q8. 프롬프트 인젝션 공격에 대한 대응은?

**A:** 34개 패턴(13개 기본 + 21개 OWASP 기반 확장)을 가중 점수로 탐지합니다. "ignore all previous instructions"(40점), "system prompt"(30점), SQL 인젝션 키워드 DROP/UNION SELECT(40~50점), Base64 인코딩 우회(30점), 한국어 인젝션 패턴(25~35점) 등을 감지합니다. 점수 합산이 30점 초과면 의심 경고, 70점 초과면 즉시 차단합니다. 추가로 입력 새니타이징 3단계(strict/moderate/permissive) 모드를 제공하며, 의료 환경에서는 strict 모드를 기본 적용합니다.

---

## Q9. 다중 턴 대화(Multi-turn Conversation)는 어떻게 구현했나요?

**A:** LangGraph StateGraph를 활용한 멀티 에이전트 워크플로우입니다. 4개 노드가 순차 실행됩니다:
1. **참조 탐지** — "방금", "이전 결과", "그 환자" 등 문맥 참조어 감지
2. **컨텍스트 해석** — 이전 대화의 SQL 결과를 참조하여 문맥 복원
3. **질의 보강** — 원래 질문에 문맥 정보를 결합
4. **상태 갱신** — 대화 상태 체크포인트 저장

예를 들어, "당뇨 환자 수 알려줘" → "그중 고혈압 동반 환자는?" 같은 연속 질의에서 이전 SQL의 WHERE 조건을 자동으로 이어받아 정확한 결과를 반환합니다.

---

## Q10. OMOP CDM을 선택한 이유는?

**A:** OMOP CDM은 OHDSI 국제 컨소시엄의 표준 임상 데이터 모델로, 전 세계 3,000여 기관이 채택하고 있습니다. 아산병원의 기존 EMR 데이터를 OMOP CDM으로 변환하면:
- 국제 다기관 공동연구에 바로 참여 가능
- ATLAS, ACHILLES 등 표준 분석 도구 활용 가능
- SNOMED CT, ICD-10, LOINC 등 국제 표준 용어와 자연스럽게 연결
- 비정형 데이터도 `note`, `note_nlp` 표준 테이블에 적재하여 일관된 분석 체계 유지

현재 Synthea 합성 데이터 기준 76,074명, 9,200만 행이 적재되어 있으며, 실 데이터 전환 시 동일 파이프라인을 그대로 사용합니다.

---

## Q11. GPU 서버 구성과 모델 배포 전략은?

**A:** 현재 3개 모델을 GPU에서 운영합니다:

| 모델 | 용도 | VRAM | 배포 |
|------|------|------|------|
| XiYanSQL-QWen2.5-3B | Text2SQL | 6.2GB | 로컬 Docker (vLLM) |
| Qwen3-32B-AWQ | 범용 LLM | 22.4GB | 원격 GPU (SSH 터널) |
| BioClinicalBERT | NER | 0.3GB | 원격 GPU (SSH 터널) |

AWQ(Activation-aware Weight Quantization)를 적용하여 32B 모델을 단일 GPU에서 운영 가능하게 했습니다. vLLM을 추론 엔진으로 사용하여 배치 처리와 KV 캐시 최적화로 동시 요청 처리 성능을 확보했습니다.

---

## Q12. 기존 HIS(AMIS 3.0)와의 연동 방안은?

**A:** 제안 아키텍처의 Ingestion Layer에서 CDC(Change Data Capture)를 통해 실시간 동기화합니다. HIS의 처방/EMR/간호/검사/투약/수술/마취 등 데이터를 실시간으로 Landing Zone에 수집하고, Processing Layer에서 정형 데이터는 Validate-Clean-Standardize를, 비정형 데이터는 NLP/NER 구조화를 거쳐 OMOP CDM 표준으로 변환합니다. Kafka 기반 CDC로 SLA 10초 이내 실시간 반영을 목표합니다.

---

## Q13. 비정형 데이터 소스(nGLIS, PACS, Bio-signal 등)는 어떻게 처리하나요?

**A:** 소스별 파이프라인이 다릅니다:
- **PACS(의료영상)** → DICOM 파싱 파이프라인 (pydicom 메타 추출 → imaging_study 적재)
- **nGLIS(유전체)** → 신호/유전체 파싱 파이프라인 (VCF/FASTQ 파싱, 2단계 확장 예정)
- **검사결과 Free-Text** → 임상노트 구조화 파이프라인 (LLM 섹션분리 + NER → note/note_nlp 적재)
- **Digital Pathology** → 이미지 메타데이터 추출 + S3 원본 보관
- **Bio-signal** → 시계열 파싱 (3단계 확장 예정)

모든 비정형 처리 결과는 `unstructured_job` 테이블에서 통합 추적하며, 원본은 MinIO S3에 영구 보관합니다.

---

## Q14. 데이터 품질은 어떻게 관리하나요?

**A:** MCP(Model Context Protocol) 도구로 실시간 데이터 품질 검사를 제공합니다. `check_data_quality` 도구가 OMOP 테이블별 NULL 비율, 범위 이탈, 참조 무결성을 자동 검증합니다. 거버넌스 레이어에서는 민감도 3등급 분류(극비/민감/일반), 컬럼별 자동 태깅(LLM 기반), 데이터 리니지 추적을 제공합니다. 현재 condition_occurrence 테이블 기준 99.7% 완성도를 확인했습니다.

---

## Q15. 성능은 어떤가요? 대용량 데이터에서도 실시간 응답이 가능한가요?

**A:** OMOP CDM 9,200만 행 기준 성능입니다:
- **Text2SQL 질의** — 일반 질의 2~5초, 복잡한 집계 질의 10~15초
- **NER 분석** — 텍스트 1건 500ms 이내
- **임상노트 구조화** — 1건 약 10초 (LLM 섹션분리 포함)
- **대시보드 통계** — measurement 테이블(3,660만 행) 풀스캔은 2분 소요되어 5분 캐시 + 백그라운드 리프레시 전략을 적용했습니다

주요 테이블에 인덱스를 추가하고, 무거운 쿼리는 Redis 캐싱을 적용하여 체감 응답 시간을 1초 이내로 유지합니다.

---

## Q16. 개인정보보호는 어떻게 처리하나요?

**A:** 다층 보호 체계입니다:
- **입력 단계** — 주민등록번호, 전화번호, 이메일 자동 탐지 및 마스킹
- **저장 단계** — 민감도 3등급(극비/민감/일반) 자동 분류, 극비 데이터 접근 로깅
- **API 단계** — JWT 인증 + CSRF 토큰 + Rate Limiting + 감사 로그
- **AI 응답 단계** — LLM 응답에서 PII 재유출 방지 검증
- **네트워크 단계** — 보안 헤더 미들웨어(X-Frame-Options, CSP, HSTS)

IRB 심의 대응을 위해 모든 AI 요청의 감사 로그를 CSV로 내보낼 수 있습니다.

---

## Q17. 다른 병원 CDW 솔루션과 비교했을 때 AI 차별점은?

**A:** 세 가지 핵심 차별점이 있습니다:
1. **비정형→정형 자동 변환** — 대부분의 CDW는 정형 데이터만 다루지만, 본 플랫폼은 임상노트/DICOM/유전체를 자동으로 OMOP CDM 표준 테이블에 적재합니다
2. **자연어 질의** — 연구자가 SQL을 몰라도 "당뇨 환자 중 HbA1c 8 이상인 사람 수"라고 물으면 즉시 결과를 반환합니다
3. **AI 안전성 내장** — 프롬프트 인젝션 방어, PII 마스킹, SQL 환각 탐지가 플랫폼 레벨에서 기본 제공되어 별도 보안 솔루션이 불필요합니다

---

## Q18. 모델 업데이트나 교체는 어떻게 하나요?

**A:** 멀티 프로바이더 아키텍처로 설계되어 있어 모델 교체가 용이합니다. 환경변수(`LLM_PROVIDER`) 하나로 XiYanSQL, Qwen, Claude, Gemini 간 전환이 가능하고, AI Ops 모듈에서 모델 레지스트리 관리, 헬스체크, A/B 테스트를 지원합니다. 새 모델을 등록하고 트래픽을 분할하여 기존 모델과 성능을 비교한 후 점진적으로 전환할 수 있습니다. vLLM 추론 엔진을 사용하므로 HuggingFace 호환 모델이면 즉시 배포 가능합니다.

---

## Q19. 확장성은 어떤가요? 데이터가 10배 늘어나면?

**A:** 각 레이어별 수평 확장이 가능합니다:
- **LLM 추론** — vLLM의 텐서 병렬화로 멀티 GPU 확장, 또는 추가 GPU 서버를 SSH 터널로 연결
- **벡터 DB** — Milvus는 분산 클러스터 모드 지원 (현재 standalone → cluster 전환 가능)
- **OMOP DB** — PostgreSQL 읽기 복제본 추가, 또는 Citus 분산 확장
- **오브젝트 스토리지** — MinIO 분산 모드로 노드 추가
- **API 서버** — FastAPI 멀티 워커(현재 4워커) + 로드밸런서로 수평 확장

Data Lakehouse 아키텍처(Landing→Clean→Curated Zone)로 설계되어 있어 데이터 증가에 따른 아키텍처 변경 없이 스토리지만 확장하면 됩니다.

---

## Q20. 구축 후 연구자가 실제로 어떻게 활용하나요?

**A:** 연구자 페르소나별 활용 시나리오입니다:

**임상의(외래/병동):**
- 자연어로 "최근 1년간 당뇨+고혈압 동반 환자 중 eGFR 30 미만인 환자 수" 질의 → 즉시 결과

**임상연구자:**
- 코호트 빌더로 연구 대상군 추출 → JupyterLab에서 통계 분석 → 결과 BI 대시보드에 시각화

**데이터 분석가:**
- 비정형 구조화 탭에서 임상노트 배치 처리 → OMOP note_nlp에서 NER 결과 기반 코호트 추출

**외부 공동연구:**
- OMOP CDM 표준 기반 데이터 내보내기 → OHDSI ATLAS 호환 패키지로 다기관 연구 참여

모든 활동은 포털 단일 인터페이스에서 이루어지며, SQL 지식 없이도 자연어 질의와 시각화를 통해 데이터에 접근할 수 있습니다.
