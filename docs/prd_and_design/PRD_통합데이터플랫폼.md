# PRD: 서울아산병원 통합 데이터 플랫폼 (IDP)

## 문서 정보
- **버전**: 2.0
- **작성일**: 2026-02-06
- **최종수정일**: 2026-02-06
- **프로젝트명**: 서울아산병원 통합 데이터 플랫폼 구축
- **사업기간**: 계약 후 18개월
- **제안사**: 데이터스트림즈

---

## 1. 개요

### 1.1 배경
서울아산병원은 국내 최대 의료기관으로 방대한 규모의 의료 데이터를 보유하고 있으나, 현재 CDW(Clinical Data Warehouse)와 EDW(Enterprise Data Warehouse)가 분리 운영되어 데이터 사일로 현상이 발생하고 있다. 또한 데이터 접근성 저하, 비효율적인 수작업 SR 기반 데이터 추출 프로세스, 레거시 인프라 한계 등의 문제가 있다.

### 1.2 목표
- 데이터 레이크하우스 아키텍처 기반 통합 데이터 플랫폼 구축
- CDW/EDW 통합 및 Self-Service 데이터 분석 환경 제공
- AI 기반 지능형 데이터 서비스 및 MCP 환경 구축
- 통합 데이터 거버넌스 체계 확립

### 1.3 핵심 지표 (KPI)
| 지표 | 현재 | 목표 |
|------|------|------|
| 데이터 추출 소요시간 | 수일~수주 | 수분~수시간 |
| Self-Service 사용률 | 0% | 70% |
| 데이터 표준화율 | - | 90% |
| API 기반 연동 시스템 수 | - | 10+ |

---

## 2. 시스템 아키텍처

### 2.1 전체 구성도

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         데이터 포털 (Data Portal)                         │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐    │
│  │ 데이터 카탈로그 │ │ 시각화/BI    │ │ 분석 환경    │ │ AI Assistant │    │
│  └──────────────┘ └──────────────┘ └──────────────┘ └──────────────┘    │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
┌─────────────────────────────────────────────────────────────────────────┐
│                      데이터 거버넌스 (Governance)                         │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐      │
│  │ 표준 관리 │ │ 메타데이터│ │ 품질 관리 │ │ 보안/권한 │ │ 비식별화  │      │
│  └──────────┘ └──────────┘ └──────────┘ └──────────┘ └──────────┘      │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
┌─────────────────────────────────────────────────────────────────────────┐
│                    데이터 레이크하우스 (Lakehouse)                        │
│  ┌───────────────────────────────────────────────────────────────────┐  │
│  │ Query Engine (DuckDB/Trino)  │  OLAP Layer  │  Semantic Layer      │  │
│  └───────────────────────────────────────────────────────────────────┘  │
│  ┌───────────────────────────────────────────────────────────────────┐  │
│  │        Object Storage (Iceberg/Delta Lake)  - 2PB 규모             │  │
│  │    ┌──────────┐    ┌──────────┐    ┌──────────┐                   │  │
│  │    │ Bronze   │ -> │ Silver   │ -> │ Gold     │                   │  │
│  │    │ (Raw)    │    │ (정제)    │    │ (마트)   │                   │  │
│  │    └──────────┘    └──────────┘    └──────────┘                   │  │
│  └───────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
┌─────────────────────────────────────────────────────────────────────────┐
│                       데이터 파이프라인 (Pipeline)                        │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐    │
│  │ CDC (Debezium)│ │ ETL (Airflow)│ │ 스트리밍     │ │ 비정형 처리  │    │
│  └──────────────┘ └──────────────┘ └──────────────┘ └──────────────┘    │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
┌─────────────────────────────────────────────────────────────────────────┐
│                          원천 시스템 (Source)                            │
│  ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐     │
│  │ EMR    │ │ PACS   │ │ LIS    │ │ OCS    │ │ ERP    │ │ 기타   │     │
│  └────────┘ └────────┘ └────────┘ └────────┘ └────────┘ └────────┘     │
└─────────────────────────────────────────────────────────────────────────┘
```

### 2.2 소프트웨어 스택 (제안 솔루션)

#### 2.2.1 통합 데이터 플랫폼 소프트웨어

| 구분 | 솔루션 | 제조사 | 적용 영역 | 수량 |
|------|--------|--------|----------|------|
| 통합 레이크하우스 | **TeraONE** | 데이터스트림즈 | 빅데이터 분석 및 CI/CD 파이프라인 | 2식 |
| DB 암호화 | **Petra Cipher** | 신시웨이 | DB 암호화 | 1식 |
| API Gateway | **i-ONE API Gateway** | 이데아텍 | API 통합 관리, 인증·권한·트래픽 제어 | 1식 |
| ETL 시스템 | **TeraStream** | 데이터스트림즈 | 대용량 데이터 수집·정제·적재 핵심 ETL | 2식 |
| CDC | **DeltaStream** | 데이터스트림즈 | DB 변경 로그 기반 실시간/준실시간 동기화 | 2식 |
| 데이터 가상화 | **TeraONE SuperQuery** | 데이터스트림즈 | 분산 데이터 단일 질의 및 고속 조회 | 2식 |
| IT 메타데이터 | **MetaStream** | 데이터스트림즈 | 데이터 표준·정의·구조·흐름 전사 메타데이터 관리 | 1식 |
| Biz 메타데이터 | **MetaStream for BizData** | 데이터스트림즈 | 업무·연구 관점 비즈니스 메타데이터 관리 | 1식 |
| 데이터 품질 | **QualityStream** | 데이터스트림즈 | 데이터 정합성·완전성·유효성 검증 체계 | 1식 |
| 비정형 가명처리 | **UDmaster** | 데이타스 | AI 기반 텍스트, 음성, 영상, 이미지 비식별화 | 1식 |
| 데이터 카탈로그 | **IRUDA** | 데이타스트림즈 | 데이터 카탈로그·품질·통계 통합 셀프서비스 포털 | 1식 |
| BI/시각화 | **BIMATRIX AUD7.0** | 비아이매트릭스 | 셀프서비스 BI 및 고성능 대시보드 | 1식 |

#### 2.2.2 AI Assistant 소프트웨어 (LLM 서비스)

| 구분 | 솔루션 | 역할 |
|------|--------|------|
| Main Control Server | AI Agent/LLMOps Service | MCP 기반 에이전트 오케스트레이션 |
| Model Server | Image/Model Repository | 모델 관리 및 배포 |
| GPU Server #1~4 | LLM Operation Service | Qwen3-235B 서빙, vLLM PagedAttention |
| Vector DB | Milvus | RAG 임베딩 저장소 (GPU 가속/분산 검색) |
| Worker Node | TeraONE IDEA Service | ML/DL 분석 플랫폼 |

#### 2.2.3 공유 워크스페이스 (ML·DL 분석 플랫폼)

| 구분 | 역할 |
|------|------|
| TeraONE IDEA | JupyterLab, RStudio, Container 기반 분석 환경 |
| Sandbox | 격리된 개인 분석 공간 |
| docker/Container | 컨테이너 기반 환경 관리 |
| Kube API Server | Kubernetes 클러스터 관리 |

### 2.3 데이터 레이크하우스 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                서울아산병원 지능형 데이터 패브릭 플랫폼                        │
├─────────────────────────────────────────────────────────────────────────────┤
│ 데이터 소스                                                                   │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │ 정형데이터: HIS(AMIS 3.0) - 처방, EMR, 간호, 검사, 투약, 중환자실 등      │  │
│  │ 비정형데이터: nGLIS, PACS, Bio-signal, Digital Pathology, Free-Text     │  │
│  │ 기존시스템: EDW, CDW                                                    │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
├─────────────────────────────────────────────────────────────────────────────┤
│ 데이터 수집/변환/적재                                                         │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │ 데이터 취득(DI)     │ 데이터 가상화       │ 데이터 저장소              │  │
│  │  - Streaming       │  - TeraONE SuperQuery│  - Data Lakehouse        │  │
│  │  - CDC (DeltaStream)│  - In-Memory Cache   │  - ODS(L0) → DW(L1)     │  │
│  │  - Batch (TeraStream)│                     │     → Data Mart(L2)     │  │
│  │                     │                     │  - File Format: Parquet  │  │
│  │ ETL 시스템          │ LDAP 서버           │    JSON, CSV, ORC        │  │
│  │  - TeraStream       │  - Apache Directory  │  - Table Format: Iceberg │  │
│  │  - Data Cleansing   │                     │  - Object Storage: S3    │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
├─────────────────────────────────────────────────────────────────────────────┤
│ 데이터 거버넌스                                                               │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │ 통합 관리          │ 데이터 카탈로그                                    │  │
│  │  - 비식별화시스템   │  - 메타관리(IT메타): MetaStream                    │  │
│  │  - 데이터/시스템    │  - 비즈메타 관리(Biz메타): MetaStream for BizData  │  │
│  │    관리체계        │  - 데이터 품질관리: QualityStream                  │  │
│  │  - 관리 AI 시스템   │  - 추천관리: IRUDA                                │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
├─────────────────────────────────────────────────────────────────────────────┤
│ 데이터 활용/분석                                                              │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │ 활용 도구                  │ AI Assistant (LLM 기반 AI)                 │  │
│  │  - 공유 워크스페이스       │  - NL2SQL (XiYanSQL)                       │  │
│  │    (ML·DL 분석환경)       │  - 비정형데이터 구조화                       │  │
│  │  - TeraONE IDEA           │  - Smart Catalogue                         │  │
│  │  - JupyterLab, RStudio    │                                            │  │
│  │  - Sandbox, Container     │ 데이터 제공서비스      │ CI/CD             │  │
│  │                           │  - 데이터/파일/API     │  - CI/CD 엔진     │  │
│  │ 데이터 분석 환경 연계      │  - Agent             │  - CD/GitOps       │  │
│  │  - Hybrid T2              │                       │                    │  │
│  │  - 폐쇄 분석실            │                       │                    │  │
│  │  - 멀티 클라우드          │                       │                    │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
├─────────────────────────────────────────────────────────────────────────────┤
│ 포털                                                                         │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │ 지표/통계/시스템          │ 검색/조회/추출                              │  │
│  │  - 포털/지표기획          │  - 데이터 탐색                              │  │
│  │  - UI/UX 구성             │  - 데이터 공유                              │  │
│  │  - BI/시각화 시스템       │  - 템플릿 제공                              │  │
│  │    (BIMATRIX)            │  - 시각화 분석                               │  │
│  │                           │  - 코호트 샘플 데이터 제공                  │  │
│  │                           │  - 라이브러리 등록                          │  │
│  │                           │  - 비식별 EMR Viewer                        │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.4 기술 스택 (오픈소스 연동)

| 레이어 | 기술 | 용도 |
|--------|------|------|
| 스토리지 | Apache Iceberg | 오픈 테이블 포맷 |
| 쿼리 엔진 | Trino, Spark3, Hive | OLAP 쿼리 처리 |
| 메시징 | Apache Kafka | 스트리밍 데이터 처리 |
| 클러스터 관리 | YARN, ZooKeeper | 리소스 관리 |
| 분산 스토리지 | HDFS, MinIO | 오브젝트 스토리지 |
| 모니터링 | Ambari Metrics, Grafana | 시스템 모니터링 |
| 벡터DB | Milvus | RAG/임베딩 저장 (GPU 가속) |
| ML 추적 | MLflow | 모델 버전 관리 |
| API Gateway | i-ONE API Gateway | API 관리 |
| AI/LLM | Qwen3-235B, Multi-LLM | AI 서비스 |
| MCP | Model Context Protocol | AI 에이전트 연동 |

---

## 3. 기능 요구사항

### 3.1 시스템 기능 요구사항 (SFR)

#### SFR-001: 공통 요구사항
- 목표 시스템 구성에 대한 세부 방안 제시
- 비정형 데이터를 고려한 ODS/DW/DM 설계
- Web 기반 포털 시스템 구축
- 확장성 보장 (대량분석, 데이터 급증, IoT 실시간 분석 대응)

#### SFR-002: 분석 데이터마트 설계 및 구축
- CDW/EDW 통합 모델 기반 일원화된 분석 서비스
- 운영계 시스템과의 데이터 정합성 확보
- OLAP 지원 시스템 구성
- Fact/Dimension 테이블 최적 분할 구성
- 서울아산병원 데이터 표준화 규정 준수

#### SFR-003: ETL 개발
- ETL 솔루션 기반 기능 구현
- 병목 현상 식별 및 최적화
- 준 실시간 데이터 처리 (30분 간격)
- 다양한 이기종 소스 지원
- GUI 환경 ETL 개발
- 스케줄링 및 자동 실행, 모니터링

#### SFR-004: 데이터 분석 환경 제공
- 웹 기반 데이터 분석 도구 (JupyterLab, R)
- 다양한 분석 스크립트 언어/버전 지원
- 프로젝트별 자원 관리 및 모니터링
- 분석 작업 공유 및 결과 활용

#### SFR-005: 분석 플랫폼 구축
- 통합 데이터 플랫폼 데이터셋 활용 가상 연구 환경
- 온프레미스 클라우드 시스템 구성

---

### 3.2 데이터 취득 요구사항 (DIR)

#### DIR-001: 데이터 취득 방식 일관성 유지
- 실시간 스트림, 배치 프로세스 지원
- 취득 절차/기준 통제 관리 도구
- 테이블 간 종속 관계 파악
- 오류 발생 시 Alert 기능 (아산웍스 연동)

#### DIR-002: 통일된 데이터 취득 기술 확보
- 이기종 DB, 파일 형태 관계없이 동일 기술 기반 작업
- 다양한 데이터 포맷 취득 작업 자동 생성/템플릿
- Native 커넥터 다수 보유 (RDBMS, NoSQL, 클라우드 등)
- MDX, JSON, XML, HL7 FHIR 등 의료 특화 포맷 필수 지원
- 원천 시스템 메타데이터 자동 동기화

#### DIR-003: 원천데이터 변화 대응
- 스키마 변경 탐지 및 자동 처리
- 변경 사항 Logging/Monitoring
- 실시간 스트리밍 ↔ 배치 프로세스 전환

#### DIR-004: 데이터 Pipeline 구축
- 신규 마트 설계 반영 Pipeline
- CDM, PMS, REDCap 등 유관 시스템 이관용 Pipeline
- Landing Zone 취득 템플릿 기반 자동화

#### DIR-005: 변경 데이터 캡처 (CDC)
- 트랜잭션 로그 기반 실시간 캡처 (INSERT/UPDATE/DELETE)
- PostgreSQL, MySQL, SQL Server, Oracle, MongoDB 커넥터
- Iceberg 등 테이블 형식 연계
- 오프셋 기반 작업 재개

---

### 3.3 데이터 거버넌스 요구사항 (DGR)

#### DGR-001: 데이터 표준 관리
- 다양한 원천 시스템 데이터 용어/값/코드 통합 표준화
- AMIS 3.0 표준 메타 시스템 연계
- 시스템/화면 표준 용어 독립 관리
- 용어 분류체계, 표준 지표 정의

#### DGR-002: 메타데이터 관리 체계
- 데이터 매핑, 작업 조건/검증/오류 기준 관리
- 데이터 정의/스키마 변경 워크플로우
- 데이터 처리 규정 준수 모니터링
- Biz 메타데이터 적용 Pipeline Job 현황

#### DGR-003: 데이터 카탈로그
- 데이터 정의/생성/소유권/공유 관리 프로세스
- 표준 메타 + Biz 메타 집약 카탈로그 생성
- 데이터 오너쉽 정의 및 공유 대상 관리
- API, XML, JSON, SQL, View 등 카탈로그 제공

#### DGR-004: 데이터 품질관리
- 상시 품질관리 자동화 시스템
- 적재 시 자동 품질 검증 (필수 컬럼, 타입, 범위, 중복, NULL)
- 오류 발생 시 담당자 자동 통보
- 품질 검증 규칙 선언적 정의

#### DGR-005: 데이터 보안관리
- 데이터 보안과 사용 권한 명확 분리
- 테이블/컬럼 단위 보안 관리
- Row-level, Column-level, Cell-level 3단계 보안
- 컨텍스트(시간, 위치, 목적) 기반 접근 권한

#### DGR-006: 데이터 비식별 처리
- 취득 과정, Pipeline 각 단계, 포털 서비스 비식별/재식별 적용
- 비식별/재식별 처리 모니터링

#### DGR-007: 데이터 권한 관리
- 역할 기반 권한 부여 (RBAC)
- AMIS 3.0 EAM 역할 연계
- 테이블/컬럼/로우별 권한 통제
- 재식별 권한 등 특수 권한 역할 정의

#### DGR-008: 데이터 복구 방안
- 대량 데이터 복구 관리
- 보안 사고 시 데이터 복구 절차

#### DGR-009: 지능형 거버넌스 자동화
- 쿼리 패턴 분석 기반 자동 인덱싱/파티셔닝
- 자주 사용 조인 패턴 자동 캐싱
- 피크 시간대 예측 및 리소스 사전 할당
- 데이터 품질 이상 자동 감지/알림
- 메타데이터 변경 영향도 자동 분석

---

### 3.4 데이터 포털 요구사항 (DPR)

#### DPR-001: 포털 UI/UX 설계
- 메인화면: CDW/EDW 통합 레이크하우스 대시보드
- 우측 AI Assistant Side-bar (호출/접기 가능)
- 자연어 데이터 검색, 필터링, 쿼리 생성 요청
- 대화 내용 타임라인 기록 및 상태 복원
- 데이터 관계 시각화 (Tree/Graph View)
- 통합 검색창 (자동완성, 오타 보정)
- AI 요약 답변 + Raw-data/연관 데이터 리스트
- Faceted Search (다차원 필터링)
- 데이터 미리보기 (스키마, 샘플 데이터, 썸네일)
- 스냅샷/레시피 기반 데이터 재현성 확보
- Python/R 즉시 로딩 코드 제공
- Community 탭 (Q&A, 이슈 트래킹)

#### DPR-002: 지능형 데이터 카탈로그 및 탐색
- 메타데이터 기반 통합 검색
- 연관 데이터셋 자동 추천
- Data Lineage 시각화
- Semantic Layer 적용
- 드래그 앤 드롭 데이터 조합
- 마스터 분석 모델 등록/공유
- 사용 이력 기반 추천 알고리즘

#### DPR-003: 임상/연구 특화 고급 데이터 추출
- GUI 기반 집합 연산 (교집합, 차집합, 여집합)
- Venn Diagram 시각화
- Index Date 기준 전후 이벤트 결합 로직
- 코호트 필터링 시각화 (CONSORT Diagram)
- 단계별 잔존/탈락 환자 수 실시간 계산
- Drill-down 환자 리스트 조회
- Chart Review (시계열/이벤트 중심 진료기록)

#### DPR-004: 셀프서비스 시각화 및 BI
- 다양한 원천/파일 직접 연동 및 Data Blending
- No-Code 차트 생성 (Drill-down/up, Cross-filter)
- SQL Editor 내장
- 원본 데이터 역추적 검증
- 정형 리포트 생성, Excel 웹 리포트 변환
- 비동기 쿼리, 결과 캐싱
- PDF, Excel, PPT, HWP 보고서 변환

#### DPR-005: 포털 운영 관리 및 거버넌스
- 사용자 권한 관리 (연구자, 행정, 관리자)
- 조회/미리보기/다운로드 권한 차등 부여
- 데이터셋 공유 설정 (개인/그룹/전체)
- 접근 로그 및 버전 관리

---

### 3.5 AI 적용 요구사항 (AAR)

#### AAR-001: AI 기반 지능형 서비스

##### 1. 사용자용 AI Assistant

###### 1-1. Natural Language Interface
- **Text2SQL 최적화**
  - Prompt Enhancement로 불완전한 키워드 입력을 완전한 질의문으로 자동 확장
  - SQL 없이도 필요한 데이터를 조회할 수 있는 Interactive Agent 구현
  - 목표 정확도: NL2SQL 실행 정확도 95% 이상

- **95% 정확도 달성 5단계 파이프라인**
  | 단계 | 내용 | 정확도 기여 |
  |------|------|------------|
  | 01 | 의료 용어 해석 (OMOP CDM 매핑, ICD-10/LOINC 변환) | 기본 65-70% |
  | 02 | MetaStream 스키마 라우팅 (IT메타/비즈메타 통합, 양방향 검색) | +25-30% 리콜 향상 |
  | 03 | 다중 후보 SQL 생성 (Qwen3-235B 추론, 자기 일관성 투표) | +3-5% 정확도 향상 |
  | 04 | 실행 검증 및 교정 (SQL 실행 테스트, 오류 피드백 루프) | +5-8% 오류 감소 |
  | 05 | PubMed 근거 부착 (최신 가이드라인 검색, 논문 출처 명시) | 42-68% 환각 감소 |

- **비즈메타와 IT메타 통합 (MetaStream)**
  - 비즈메타: 비즈니스 용어 사전, 의료 표준 매핑, 데이터 소유자/스튜어드, 품질 메트릭
  - IT메타: 테이블/컬럼 물리 스키마, 외래키(FK) 관계, 인덱스 구성, 데이터 리니지
  - 4,000개 테이블 간 JOIN 경로와 인덱스 정보를 통해 최적의 쿼리 실행 계획 수립

- **MetaStream 알고리즘**
  - 비즈메타 의미 검색과 IT메타 관계 분석을 병렬로 수행하는 양방향 검색 알고리즘
  - RRF Fusion 통합 랭킹 (α=0.6 비즈메타 가중)으로 실제 의사 질의와 가장 잘 맞는 스키마 우선 선택

- **PubMed MCP 통합**
  - MCP 프로토콜 기반 PubMed 3500만 개 의학 문헌 실시간 검색 통합
  - 모든 AI 응답에 논문 출처 PMID 자동 부착
  - 최신 임상 가이드라인과 진단 기준을 SQL 생성 과정에 반영
  - 환각 감소 효과: 기본 LLM 40% → RAG + PubMed 8% (내부 PoC 예시)

###### 1-2. Context-Aware Chat
- **ConversationMemory 아키텍처**
  - LangGraph State Management 기반 대화 세션별 컨텍스트 메모리 유지
  - SQL 생성은 하지 않으며, NL2SQL 서비스(XiYan SQL)에 전달할 enriched_context 구성이 핵심 역할
  - "방금 조회한 환자 리스트에서 고혈압 진단이 있는 케이스만 필터링해줘" 등 문맥 기반 질의 지원

- **워크플로우 (4개 노드)**
  ```
  START → reference_detector → [분기]
    ├─ has_references → context_resolver → query_enricher → state_updater → END
    └─ no_references → query_enricher → state_updater → END
  ```
  - `reference_detector`: 한국어 참조 표현 탐지 ("방금", "그 환자", "그 중에서", "추가로")
  - `context_resolver`: 이전 QueryContext 기반 참조 해석 (시간적/엔티티/결과/조건 4유형)
  - `query_enricher`: 이전 SQL·조건·결과건수를 포함한 enriched_context 프롬프트 구성
  - `state_updater`: query_history 업데이트, 세션 만료 관리

- **enriched_context → XiYan SQL 연동**
  - ConversationMemory 출력(enriched_context)을 XiYan SQL에 전달하여 효율적 SQL 생성
  - XiYan SQL이 이전 조건을 유지하면서 하나의 평탄한 SQL 생성 (서브쿼리 중첩 없음)
  - SQL 실행 후 `record_query_result()`로 결과를 상태에 기록 → 다음 턴에서 참조

- **세션 상태 저장소**
  - thread_id, query_history, last_query_context, enriched_context 관리
  - Redis 캐시 빠른 조회 + PostgreSQL 영구 저장 (LangGraph Checkpoint)
  - 30분 비활성 시 자동 만료, 최대 50개 턴 히스토리 유지

- **연속 질의 해석 (한국어 참조 패턴)**
  | 유형 | 패턴 예시 | 해석 |
  |------|----------|------|
  | 시간적 | "방금", "이전", "아까", "직전" | 이전 쿼리 결과 전체 참조 |
  | 엔티티 | "그 환자", "해당 환자", "위 환자" | 이전 결과의 환자 집합 참조 |
  | 결과 | "그 중", "거기서", "위 결과" | 이전 결과에서 추가 필터링 |
  | 조건 | "추가로", "더 좁혀", "그리고" | 이전 조건 유지 + 새 조건 추가 |

###### 1-3. 데이터 해석 (AutoExplain)
- **자동 요약 기능**
  - Qwen3-235B 기반 AutoExplain 엔진으로 조회된 데이터셋의 기술통계량과 분포 특성 자동 분석
  - 의료 정상 범위 및 임상 가이드라인과 비교하여 임상적 의미 해석 제공
  - 예: "평균 연령 58.3세 남성 62퍼센트 HbA1c 평균 7.8퍼센트로 정상 범위 6.5퍼센트 미만 대비 1.3%p 높아 심혈관 합병증 위험이 증가한 상태입니다"

- **AutoExplain 분석 단계**
  1. 기술통계 계산 (평균, 중앙값, 표준편차, 사분위수)
  2. 의료 정상 범위 조회 (OMOP CDM + PubMed 가이드라인)
  3. 편차 분석 (정상 vs 실측 비교)
  4. 임상적 의미 해석
  5. 자연어 요약 생성 (Qwen3-235B 프롬프트)

- **자동 시각화**
  - 데이터 특성별 차트 자동 선택
  - 연속형: 히스토그램, 박스플롯 / 범주형: 막대 그래프
  - Matplotlib/Seaborn PNG 생성

##### 2. 비정형 데이터 구조화

###### 2-1. BioClinicalBERT Medical IE
- 의료 NER 기술과 OMOP CDM 자동 매핑 체계를 통해 1PB 규모의 비정형 EMR 의무기록을 구조화된 데이터 자산으로 전환
- Medical NER: BioClinicalBERT (F1 Score 0.950 on i2b2 2006)
- 한국어 처리: bi-KM-BERT (Macro F1 0.946)
- 표준 용어: OMOP CDM 5.4 + OHDSI Athena Vocabulary

###### 2-2. CodeMapper 표준 변환
- OHDSI Athena Vocabulary 기반 CodeMapper로 BioClinicalBERT가 추출한 의료 용어를 ICD-10 질병 코드, RxNorm 약물 코드, LOINC 검사 코드로 자동 매핑
- Fuzzy Matching과 한국어 의료 용어 사전 통합으로 95% 수준의 매핑 정확도 달성
- Levenshtein Distance 계산, 유사도 임계값 85% 이상

###### 2-3. AutoTagger 비즈니스 태그
- 신규 테이블 적재 시 컬럼명 패턴 분석과 데이터 프로파일링 수행
- BGE-M3 임베딩 기반 의미 유사도 검색으로 MetaStream 비즈니스 메타데이터 카탈로그에서 기존 태그 자동 추천
- FastText 분류 모델로 진료과와 데이터 유형 예측, 민감도 수준 자동 분류

##### 3. 지능형 데이터 카탈로그

###### 3-1. BGE-M3 Semantic Search
- BGE-M3 임베딩 모델 기반 Semantic Search 기술로 단순 키워드 매칭을 넘어 의미적 유사도 계산
- 연구자가 원하는 데이터를 빠짐없이 찾을 수 있는 지능형 카탈로그 시스템 구축
- 검색 결과: 기존 대비 23.5배 향상 (내부 로그 분석 기준)

###### 3-2. LineageTracker 쿼리 로그 분석
- 분산된 시스템의 쿼리 로그를 AI엔진이 실시간 역공학 분석
- 데이터의 생성-가공-소비 흐름을 컬럼 단위까지 시각화하고 변경 영향도 즉시 예측
- AI SQL Parser & LLM 보조 (Qwen3)로 복잡한 쿼리 문장을 구조화하여 데이터 관계 파악

#### AAR-002: AI 인프라 및 아키텍처

##### 1. AI S/W 아키텍처

###### 1-1. 3계층 구조 및 PII 조건부 라우팅
- **Tier 1 (상호작용 계층)**: AI Assistant 사용자 인터페이스, WebSocket 실시간 양방향 통신
- **Tier 2 (지능형 처리 계층)**: LangGraph Supervisor (지능형 쿼리 조정자), PII 감지 에이전트, NL2SQL/PubMed MCP/용어 매핑/MetaStream 에이전트
- **Tier 3 (전문 인프라 계층)**: 온프레미스 Nutanix 인프라 (OMOP CDM DB, OHDSI 표준 용어집, MetaStream 저장소)
- Layer 3a: 온프레미스 환자 데이터 처리 / Layer 3b: 클라우드 API 익명화 데이터

###### 1-2. MCP 프로토콜 표준
- Anthropic의 MCP 프로토콜 표준 채택 (2024년 11월 발표 업계 표준)
- JSON-RPC 2.0 기반 안정적인 통신 체계와 LangChain 공식 지원
- **MCP 3대 프리미티브**:
  - Tools (실행 함수): AI가 실행할 수 있는 함수 정의
  - Resources (데이터): 구조화된 데이터와 지식 제공
  - Prompts (템플릿): 재사용 가능한 프롬프트 템플릿 제공

##### 2. GPU 클러스터

###### 2-1. 500개 동시 세션 처리 인프라
- NVIDIA H200 80GB GPU 클러스터 기반 온프레미스 인프라
- Qwen3-235B FP8 양자화 모델 서빙으로 500개 동시 세션에서 400+ req/s 처리 성능 제공
- Apache 2.0 라이선스로 소프트웨어 비용 제로화
- vLLM PagedAttention 기술로 메모리 효율 극대화하여 TCO 최소화

###### 2-2. vLLM 서빙 프레임워크
- PagedAttention으로 GPU 메모리 효율 2-4배 향상
- TTFT (첫 토큰) 50-80ms의 일관된 응답 속도로 우수한 사용자 경험 제공
- OpenAI 호환 API로 기존 시스템과의 매끄러운 통합

###### 2-3. Nutanix 하이브리드 클라우드
- 환자 데이터는 온프레미스에서만 처리하고 익명화 통계만 클라우드 활용
- AI기본법 준수 (2026년 1월 22일 시행)
- PII 라우팅 게이트웨이: 환자명/ID, 주민번호, 진료기록번호 자동 탐지

##### 3. Container 기반 확장 환경

###### 3-1. 1PB 데이터 벡터 검색 최적화
- 1PB 비정형 의료 데이터를 HNSW-PQ 양자화로 15-25TB로 압축
- Milvus Vector DB에 저장하고 하이브리드 검색 (Dense BGE-M3 + Sparse BM25)
- MedCPT 리랭킹으로 의미 검색과 정확한 용어 매칭을 동시에 제공하여 RAG 정확도 극대화

###### 3-2. 스토리지 계층화 전략
- **Hot 계층 (GPU HBM)**: 활성 KV 캐시 + 실행 중 모델 파라미터, 접근 속도 TB/s
- **Warm 계층 (NVMe SSD)**: 모델 가중치 + Milvus Vector DB, 용량 수 TB (총 300TB Usable)
- **Cold 계층 (HDD NAS)**: 학습 데이터셋 아카이브 + 원본 EMR 백업, 용량 수십 TB (총 1.7PB Usable)
- Nutanix Unified Storage로 3계층 통합 관리, Policy-based Tiering으로 접근 빈도 낮아진 데이터 자동으로 하위 계층 이관

#### AAR-003: AI 운영 및 라이프사이클 관리

##### 1. Model Lifecycle Management

###### 1-1. MLflow 기반 통합 관리
- MLflow와 Weights and Biases를 통합하여 모델 실험 추적, 하이퍼파라미터 자동 튜닝, 버전 관리 수행
- Shadow, Canary, Production 3단계 배포 전략으로 신규 모델 안전하게 도입
- **3단계 안전 배포 전략**:
  1. Shadow 배포: 실제 트래픽 패턴에서 신규 모델 동작 관찰 (로그만 기록)
  2. Canary 배포: 전체 트래픽의 5-10%만 신규 모델로 라우팅하여 점진적 노출
  3. Production 배포: Canary 단계에서 최소 2주 이상 안정적으로 운영되고 성능 지표가 기준 충족 시 전체 사용자에게 배포

##### 2. Resource Monitoring

###### 2-1. Prometheus + Grafana 실시간 체계
- Prometheus 기반 실시간 모니터링으로 NL2SQL 정확도, RAG 검색 품질, GPU 리소스 활용률을 초 단위로 추적
- 임계값 초과 시 자동 알람 발송 (Slack, 이메일)
- **모니터링 메트릭**:
  - NL2SQL 정확도: 실행 정확도(EX) 목표 95% 이상, 컴포넌트 매치(CM) 목표 98% 이상
  - RAG 검색 품질: Precision@5 목표 90% 이상, Faithfulness 목표 95% 이상
  - GPU 리소스: GPU 활용률 권장 60-85%, 메모리 사용량 최대 80GB, 온도 임계 85°C
- 사용자별 쿼터 관리: 일반 사용자 시간당 100개 쿼리 제한, 연구자 시간당 500개 쿼리

##### 3. AI Safety & Governance

###### 3-1. AI기본법 준수 체크리스트
- 2026년 1월 22일부터 시행된 AI기본법의 고위험 AI 의무사항 5가지 완전 이행
- **의무사항 준수**:
  | 의무사항 | DataStreams 구현 방안 |
  |---------|---------------------|
  | 위험관리계획 수립 | PII 자동 탐지로 개인정보 유출 방지, PubMed 근거 부착으로 환각 감소, 편향성 모니터링 대시보드 구축 |
  | 설명 가능성 확보 | NL2SQL 생성 과정 공개(질의→스키마 선택→SQL 생성), 사용된 데이터베이스 테이블과 컬럼 명시, PubMed 논문 출처 자동 부착 |
  | 이용자 보호 장치 | SQL 실행 전 구문 검증, 결과 데이터 이상치 탐지, 신뢰도 임계값 미달 AI 경고 표시, 수동 쿼리 작성 옵션 제공 |
  | 인적 관리감독 | AI는 조회 결과만 제시하고 해석은 의료진이 수행, 중요 쿼리는 승인 워크플로우 필수, 감사 로그에 승인자 기록, AI 결과 수정 권한을 의료진에게 부여 |
  | 전 과정 문서화 | 모델 학습 데이터셋 메타데이터 관리, 성능 평가 리포트 자동 생성, 모든 AI 응답 감사 로그 기록, 버전 관리 시스템 구축 |

###### 3-2. PII 자동 탐지 및 마스킹
- PII 자동 탐지 엔진으로 환자명, 주민번호 등 개인식별정보를 실시간으로 인식하고 익명화된 식별자로 치환
- K-익명성과 차등 프라이버시 기법을 적용하여 통계 분석 결과 공개 시에도 개인을 역추적할 수 없도록 보장
- **실시간 PII 탐지 및 마스킹 플로우**:
  1. 원본 쿼리: 의료진이 자연어 질의를 입력 (환자의 성명이나 식별정보가 그대로 포함되어 있음)
  2. Presidio 탐지: Microsoft Presidio가 한국어 NER 모델로 개인식별 정보를 탐지
  3. 마스킹 변환: 환자 마스터 DB와 연동하여 실명을 익명 식별자로 치환하고, 데이터베이스 조회가 가능하도록 실제 환자 ID로 매핑
- **통계 공개 시 프라이버시 보호 기법**:
  - K-익명성 (K-Anonymity): 동일한 속성을 가진 사람이 최소 k명 이상 존재하도록 데이터를 일반화
  - 차등 프라이버시 (Differential Privacy): 통계값에 수학적으로 계산된 작은 노이즈를 추가하여 특정 개인의 데이터 포함 여부를 역추적할 수 없게 만드는 기법

---

## 4. 데이터 설계 요구사항 (DIT)

### 4.1 통합 데이터 구성 체계 (DIT-001)
- 기존 DW 중복 스키마 → 통합 모델 단일화
- 오브젝트 스토리지 기반 데이터레이크 환경 적합 설계
- 데이터 증가에 따른 성능 저하 최소화
- 파티셔닝, 파일 포맷, 집계/요약 데이터 설계
- 원천 데이터 영역 / 활용 데이터 영역 구분
- 영역별 표준/비표준 용어 정책 적용
- 비정형 데이터 구조화/정형화 대상 분석

### 4.2 목적 데이터 마트 생성 및 운영 (DIT-002)
- 유사 마트 생성 최소화
- 스키마 변경 효율적 처리
- 데이터 마트 연결 최적화
- 계층적 데이터 탐색 설계
- Dimension 관리 효율성
- 표준 지표 → 데이터 마트 → 카탈로그 서비스 연결

---

## 5. 데이터 이관 요구사항 (DMR)

### 5.1 데이터 이관 절차 및 수행 계획 (DMR-001)
- 시스템 Open 이전 3개월까지 이관 계획 완료
- 문제 발생 시 대응 방안 포함
- 전체/부분 이관 전략 병원 협의
- 비식별화 처리 등 선처리 일정 계획

### 5.2 이관 데이터 검증 및 성능 측정 (DMR-002)
- 이관 데이터 검증 방법/기준/범위 계획
- 가공/조회 성능 측정 및 조치 계획
- 비식별화 등 외부 API 사용 성능 측정

---

## 6. 비기능 요구사항

### 6.1 성능 요구사항 (PER)
- **PER-001**: 안정된 서비스 성능 확보
- **PER-002**: 느린 작업에 대한 사전 경고 시스템

### 6.2 보안 요구사항 (SER)
| ID | 요구사항 |
|-----|----------|
| SER-001 | 보안 관리 |
| SER-002 | 접근 통제 |
| SER-003 | 접속기록/모니터링 |
| SER-004 | 개발 보안 |
| SER-005 | 시스템 보안 |
| SER-006 | 운영 보안 |
| SER-007 | 로그 관리 |
| SER-008 | 데이터/문서 관리 |
| SER-009 | 물리 보안 |
| SER-010 | 개인정보보호 (개인정보보호법, 생명윤리법 준수) |

### 6.3 품질 요구사항 (QUR)
- **QUR-001**: 품질보증활동
- **QUR-002**: 기능 구현의 정확성
- **QUR-003**: 상호운용성 (데이터교환성)
- **QUR-004**: 개발절차 준수/검증
- **QUR-005**: 신뢰성/확장성

### 6.4 테스트 요구사항 (TER)
- **TER-001**: 테스트 계획 수립
- **TER-002**: 데이터 적재 결과 검증
- **TER-003**: 단위 테스트
- **TER-004**: 통합 테스트
- **TER-005**: 성능/부하 테스트
- **TER-006**: 검수
- **TER-007**: 결함 관리

---

## 7. 인프라 요구사항 (ECR)

### 7.1 H/W 구성

#### 7.1.1 HCI 기반 인프라 (Nutanix)

| 구분 | 노드 구성 | 역할 |
|------|----------|------|
| 네임 노드 #1-2 | NameNode, ResourceManager, JournalNode, History Server, ZooKeeper | 데이터 레이크하우스 관리 |
| 데이터 노드 #1-12 | DataNode, NodeManager | 데이터 저장 및 처리 |
| 엣지 노드 #1 | JournalNode, TeraONE Ambari Server, TeraONE Manager, HiveServer2, Spark3, Ranger, ZooKeeper, Yarn, Hive, Iceberg, Ambari Metrics, PostgreSQL, MySQL | 클러스터 관리 |
| 데이터 가상화 노드 #1-3 | TeraONE SuperQuery, IRUDA (Module), MetaStream (Module) | 데이터 가상화 |
| Kafka 노드 #1-3 | JournalNode, Kafka Cluster, ZooKeeper | 스트리밍 |
| 형상관리서버 | Source management Service, Workflow management Service, GitServer (Gitlab), Workflow (ArgoCD/Jenkins) | CI/CD |

#### 7.1.2 GPU 클러스터 (AI Assistant)

| 구분 | 구성 | 역할 |
|------|------|------|
| Main Control Server | AI Agent/LLMOps Service, Authz (KeyCloak), Observability Components, AI Components(MCP/Skills), Container runtime, Kubernetes Components | 에이전트 오케스트레이션 |
| Model Server | Image/Model Repository, Model Management Module, Model Registry (Nexus), Container Registry (Nexus), Object Storage Component, Container runtime, Kubernetes Components | 모델 관리 |
| **GPU Server #1-4** | LLM Operation Service, Observability Components, LLM Serving Runtime, Container runtime, Kubernetes Components, **Nvidia Stack** | **NVIDIA H200 80GB × 4 per server (총 16 GPU)** |
| Vector DB | Vector DB Service, Milvus (Vector DB), Container runtime, Kubernetes Components | RAG 저장소 |
| 마스터 노드 #1-2 | TeraONE IDEA Service SW Infra, Kube API Server, Scheduler, Controller Manager, etcd | 분석 플랫폼 관리 |
| 워커 노드 #1-3 | TeraONE IDEA Service, Pod, Container, Containerd, kubelet, Kube-proxy | 분석 환경 |

#### 7.1.3 스토리지 계층화

| 계층 | 스토리지 타입 | 용량 | 용도 |
|------|------------|------|------|
| Hot | GPU HBM | - | 활성 KV 캐시 + 실행 중 모델 파라미터 |
| Warm | NVMe SSD | 300TB (Usable) | 모델 가중치 + Vector DB, Short Term 데이터 |
| Cold | HDD NAS | 1.7PB (Usable) | 학습 데이터셋 아카이브, 원본 EMR 백업, Long Term 데이터 |

- Nutanix Unified Storage로 3계층 통합 관리
- Policy-based Tiering으로 접근 빈도에 따른 자동 계층 이동

#### 7.1.4 공통 인프라

| 구분 | 솔루션 | 역할 |
|------|--------|------|
| 취약점 분석 | Secuguard SSE | 보안 취약점 분석 |
| 통합로그 | LogCops | 로그 통합 관리 |
| 백업 | Veeam SW | 백업 및 복구 |
| NCI Pro | Nutanix Cloud Infrastructure | 클라우드 인프라 관리 |
| DB 암호화 | Petra Cipher | 데이터 암호화 |
| 사용자 접근제어 | UAC | 접근 통제 |
| 서버 접근통제 | STG | 서버 접근 관리 |

- 가상화 형태 구성 (서버 가상화 또는 HCI)
- 스토리지: 2PB (숏텀 300TB, 롱텀 1.7PB)
- 네트워크 스위치: 10GbE 이상, 이중화
- 하이브리드 T2 H/W (별도 안내)

### 7.2 개발/운영 환경
- 개발 언어/Framework: 병원 협의
- CI/CD 운영 (병원 CI/CD 우선, 배포 이력/롤백 관리)
- 형상 관리 (병원 협의 솔루션)
- API 기반 데이터 유통 체계
  - API 목록 서비스, 개발자 포털(테스트베드)
  - Multi-API Gateway (트래픽 제어, 인증, 정책 관리)
  - API 라이프사이클 자동화 및 통합 모니터링

### 7.3 확장 가능한 아키텍처
- 인프라 독립적 설계
- 산업 표준 프로토콜 지원 (JDBC, ODBC, REST, GraphQL, MDX)
- 표준 인증 프로토콜 지원 (OAuth 2.0, SAML)

---

## 8. 시스템 연동 요구사항

### 8.1 내부 시스템 연동
| 시스템 | 연동 내용 |
|--------|----------|
| CDM (Common Data Model) | 데이터 활용 시스템 통합 |
| PMS (정밀의료) | 데이터 활용 시스템 통합 |
| REDCap (e-CRF) | 데이터 활용 시스템 통합 |
| 표준 용어 메타 시스템 (엔코아) | 메타 데이터 연계 |
| IRB/DRB 시스템 | 심의 상태/내용 업무 데이터 연계 |
| AMIS 3.0 EAM | 역할 기반 권한 연계 |
| 아산웍스 | Alert 알림 연동 |

### 8.2 외부 시스템 연동
- 빅데이터 분석 지원 포털 연계
- 외부 연구 협력 데이터 개방

---

## 9. 제약사항 (COR)

- **COR-001**: 병원 보유 자원 활용
- **COR-002**: 소스코드 제공 필수
- **COR-003**: 일정지연 책임

---

## 10. 프로젝트 지원 요구사항 (PSR)

- **PSR-001**: 하자/유지관리 지원
- **PSR-002**: 교육/훈련 지원
- **PSR-003**: 매뉴얼 제공
- **PSR-004**: 안정화/복구 대응

---

## 11. 추진 일정

| 단계 | 기간 | 주요 활동 |
|------|------|----------|
| 요구사항/시스템 분석 | M ~ M+2 | 현행 시스템 분석, 요구사항 정의 |
| 설계 | M+2 ~ M+6 | 아키텍처 설계, 데이터 모델링 |
| 구현 | M+6 ~ M+12 | 개발, 데이터 이관 |
| 단위/통합 시험 | M+12 ~ M+16 | 테스트, 검증 |
| 안정화 지원 | M+16 ~ M+18 | 운영 안정화 |
| 보고회 | 착수, 중간, 최종 | 진행 상황 보고 |

---

## 12. 산출물 목록

| 분류 | 산출물 |
|------|--------|
| 분석/설계 | 목표 시스템 구성도, 데이터 구성 체계도, ERD |
| 데이터 | 데이터 이관 계획서, 데이터 검증 계획서, 데이터 취득 관리 지침서 |
| 거버넌스 | 데이터 표준 관리 지침, 품질관리 지침, 보안관리 지침, 권한관리 지침 |
| 복구 | 데이터 복구 계획서 |
| 플랫폼 | 분석 플랫폼, 데이터 포털 |
| 매뉴얼 | 사용자 매뉴얼, 운영자 매뉴얼 |

---

## 13. 용어 정의

| 용어 | 정의 |
|------|------|
| CDW | Clinical Data Warehouse - 임상 데이터 웨어하우스 |
| EDW | Enterprise Data Warehouse - 전사 데이터 웨어하우스 |
| MCP | Model Context Protocol - AI 모델 컨텍스트 프로토콜 |
| CDC | Change Data Capture - 변경 데이터 캡처 |
| RAG | Retrieval-Augmented Generation - 검색 증강 생성 |
| MLOps | Machine Learning Operations - ML 운영 체계 |
| FHIR | Fast Healthcare Interoperability Resources - 의료정보 상호운용성 표준 |
| IRB | Institutional Review Board - 임상연구심의위원회 |
| DRB | Data Review Board - 데이터심의위원회 |
| CDM | Common Data Model - 공통 데이터 모델 |

---

## 14. 프로젝트 관리 요구사항 (PMR)

### 14.1 프로젝트 관리 방법론 (PMR-001)
- 고객사의 품질 관리 프로세스 및 제안사의 표준 프로젝트 관리방안 준수
- 구축 관리 Framework를 적용하여 개발 표준, 소스코드 관리, 인터페이스 표준 수립/준수

#### 14.1.1 수행 프로세스 3단계
| 단계 | 주요 활동 |
|------|----------|
| 착수/계획 | 프로젝트 수행 전략 수립, 인력투입/비용집행 계획, 위험/이슈관리 계획 |
| 분석/설계/개발/테스트 | WBS 기반 일정 및 진도관리, PMS 기반 프로젝트 관리, 단계 점검 (산출물 검토) |
| 이행/안정화 | 이행계획 수립 (리허설 수행), 기술 이전 및 교육, 안정화 지원, 프로젝트 완료보고 |

#### 14.1.2 방법론 적용 효과
1. **가시성**: 프로젝트 가시화를 통한 정확한 상태 파악
2. **납기 준수**: 일정관리 및 프로젝트 관리를 통한 납기 준수
3. **산출물**: 프로세스 및 산출물 관리를 통한 철저한 품질보증
4. **생산성**: 생산성 향상을 통한 개발기간 단축
5. **균형성**: 현행시스템과 연계 예정인 시스템의 균형 있는 개발
6. **일관성**: 단계별로 반복되는 개발과정 동안 일관성 유지
7. **유연성**: 사업 확장성을 고려한 유연성 확보

### 14.2 문서 관리 (PMR-002)
- 문서 작성/검토/승인 프로세스 적용
- 저장 및 백업, 변경에 대해 체계적으로 관리

#### 14.2.1 산출물 관리 기준
| 항목 | 설명 |
|------|------|
| 표준화 | 양식, 글꼴, 머리글/바닥글, 들여쓰기, 문서코드, 문서명 부여 규칙 |
| 이력관리 | 산출물 변경관리 체계를 통해 산출물 간 일관성 유지 |
| 승인관리 | 문서 작성, 검토, 승인 프로세스 정립 |
| 버전관리 | 테일러링 결과를 기준으로 산출물 목록 번호체계 준수 |

#### 14.2.2 작업 단계 및 산출물 목록
| 단계 | 산출물 |
|------|--------|
| 착수 단계 | 사업수행계획서, WBS, 착수보고서, 보안서약서 |
| 수행 단계 | 주간보고서, 월간보고서, 개발산출물 (상세설계서, 기능·성능테스트 계획서/결과서), 플랫폼 설계서, 시스템 구축 결과서, 시험 계획서, 시험 결과서, 보안취약점 진단서, 성능시험 결과서 |
| 준공 | 사용자 매뉴얼, 운영자 매뉴얼, 완료보고서, 준공계 |

### 14.3 보고 계획 (PMR-003)
- 사업 수행 단계별 보고서 작성 및 제출 계획 수립
- 정기/수시보고 실시

#### 14.3.1 보고서 종류 및 제출시기
| 유형 | 명칭 | 목적/내용 | 시기 | 산출물 |
|------|------|----------|------|--------|
| 주요 Milestone | 착수보고 | 프로젝트 주요일정, 추진전략, 수행방법 | 계약 후 14일 이내 | 사업수행계획서, 착수보고서 |
| 주요 Milestone | 완료보고 | 최종 성과물 보고 | 사업 종료 전 | 완료보고서 |
| 정기 | 주간보고 | 공정률 (계획/실적), 차주계획, 문제점 보고 | 매주 | 주간보고서 |
| 정기 | 월간보고 | 공정률 (계획/실적), 투입인력, 익월 추진계획 | 월말 | 월간보고서 |
| 정기 | 중간보고 | 시스템 현황분석, 중간진행 상황 | 분석/설계 완료 후 2주 이내 | 중간보고서 |
| 비정기 | 수시보고 | 필요시 관련내용 (이슈, 변경사항) | 수시 | 브리핑, 회의록 |

### 14.4 범위 관리 (PMR-004)
- 사업범위 관리를 통해 고객사 요구사항 및 업무범위 변경으로 인한 사업 RISK 최소화
- 요구사항 변경에 대한 변경관리 프로세스 수립

#### 14.4.1 범위 관리 절차
| 구분 | 수행 방안 | 산출물 |
|------|----------|--------|
| 범위 관리 계획 수립 | 프로젝트 착수 시 조기 사업범위 및 업무범위 정의, 고객사의 요구사항 수집 및 문서화, 프로젝트 관리 계획 및 절차 수립 | 착수 보고서, 요구사항 정의서 |
| 범위 관리 항목 도출 | 고객사의 변경 요청사항이 기존 프로젝트 범위에 해당하는지 여부 판단, 업무범위 및 Baseline 설정 | 범위관리 기술서, WBS |
| 범위 관리 항목 제어 | 범위 변경 필요 시 고객사와 협의를 통한 범위 변경 실시, 정책/기술 변화, 요구사항 누락 등 변경 요인 감시 | Baseline 변경표, 요구사항 추적표 |
| 변경사항 추적 및 검증 | 완료된 산출물에 대한 고객사 담당자의 승인 획득, 고객사 요구사항을 충족하였는지 평가 | 검토 결과서, 인수 테스트 결과서 |

### 14.5 일정 관리 (PMR-005)
- 체계적이고 효율적인 일정계획 수립
- 주/월간 단위로 진척 현황 측정 및 감시

#### 14.5.1 지연 정도별 대책
| 구분 | 기준 | 대책 |
|------|------|------|
| 경미 | 5% 이하 지연 | 프로젝트 지체 내 PM/PL 해결 |
| 관심 | 10% 이하 지연 | 관심대상 등록 후 주의 관리 |
| 주의 | 10% 초과 지연 | 이슈관리 등록 특별관리, 고객사와 협의 후 대책수립 |

### 14.6 품질 관리 (PMR-006)
- 프로젝트 전 과정에서 발생 가능한 비용 요소를 식별하고 통제
- 제안사의 품질 전문가 One-Team 협업 체계 구축

#### 14.6.1 품질 관리 조직 및 역할
| 구분 | 역할 및 책임 |
|------|------------|
| 고객사 | 품질 요구사항 제시, 품질 보증 계획서 승인, 성과물 확인 시험 및 승인 |
| 프로젝트 관리자 (PM) | 품질 보증 계획서 및 품질목표 승인, 품질 보증 활동 및 품질목표 달성 확인 |
| 품질 관리자 | 품질 관리 계획 및 목표 수립, 품질 검토회의 주관, 개선/시정조치 결과 확인 및 보고 |
| 전사 품질관리 조직 | 표준 및 방법론 제공 및 가이드, 품질 점검 계획 수립 및 실시, 품질 관리 활동 지원 |
| 전사 기술지원 그룹 | 품질 목표 달성 지원, 기술이슈 지원, 성능시험 지원 |
| 프로젝트 수행팀 | 품질 보증 계획에 의거 담당업무 수행, 성과물에 대한 기술적 검토 및 시험 |

#### 14.6.2 품질보증 관리 절차
| 단계 | 중점 품질보증사항 | 품질보증 활동 수행 내역 |
|------|----------------|---------------------|
| 계획 수립 - 착수 | 사업수행 조직 구성, 방법론 기반 품질 표준 정책 수립 | 품질 조직 권한 및 책임 범위 설정, 품질 절차 및 산출물 테일러링, 품질 보증 계획 수립 |
| 설계 - 분석 | 요구사항 정의 및 추적성 확보 | 품질 점검 체크리스트 작성, 요구사항 식별 및 정의 여부 검토 |
| 설계 - 설계 | 시스템/인프라 장비별 분석/설계 등 산출물 품질 검토 | 시스템/장비 설계서별 요구사항 반영 여부 검토, 설계 단계 품질 활동 Feedback 및 결과보고 |
| 구축 - 개발/구축 | 시스템 구축 품질 관리 | 시스템 개발 품질 관리 |
| 테스트 | 기능/비기능 검증 및 수행 관리, 성능/보안/가용성 시험 관리 | 단위/통합 테스트 관리 및 지원, 성능 및 가용성 시험 관리, 보안 취약점 점검 관리 |
| 이행 | 이행 계획 및 결과관리 | 이행 계획서 작성, 이행 시 비상대응방안 수립 |
| 안정화/유지보수 | 안정화/유지보수 수행 계획 및 결과 관리 | 안정화/유지보수 계획 수립 |

### 14.7 위험 관리 (PMR-007)
- 사전에 위험을 예측하고 통제할 수 있는 위험 대응 방안 수립
- 주기적으로 모니터링 및 보고 수행

#### 14.7.1 이슈 및 위험요소 별 대응 방안
| 구분 | 위험요소 | 예방 및 통제방안 |
|------|---------|----------------|
| 보안 | 수행 인력에 의한 정보 유출, 체계적인 보안 관리 부재 | 이동/퇴직 등 인력 변경 시 자료/파일 회수 및 정기적 보안 점검/보고, 보안 교육 실시, 보안서약서 제출 |
| 유지보수 업체 | 기존 유지보수 업체와의 협력 부재로 시스템 구축 문제 발생 | 시스템 구성에 대한 치밀한 계획 수립, 고객사와의 원활한 협조 체계 구축 |
| 인력 | 타 사업 수행, 개인 사정으로 인한 사직, 안전 사고 | 사업 착수 시 상세한 인력 소요 계획 수립, 프로젝트 수행 인력에 대한 평가 실시, 인력 예비 Pool 유지 |
| 품질 | 시스템의 성능 저하, 상주 요원의 맡에 대한 이해 부족 | 정형화 형태의 운영 및 장비 설정 방법 정립, 사업관리 담당자의 품질관리 수행 |
| 의사소통 | 고객과 의사소통, 사업 수행 인력 간 의사소통 어려움 | 보고, 검토회의, 일정 구축 업무 공동 수행 등을 통해 고객과 의사소통 체계 마련 |
| 협력업체 부도 | 협력업체 부도에 따라 해당 분야 업무 진행 중단 | 제안 단계 및 사업 착수 시 재무/재정 상태를 고려하여 협력 업체 선정, 예비 업체 확보 |
| 내부 시스템 연계 | 호환성 문제, 데이터 유실/변형, 인터페이스 개발 오류 | 시스템 간 통합테스트를 통해 위험 사전 예방, 중요 데이터의 값 검증 계획 수립 |

### 14.8 의사소통 관리 (PMR-008)
- 프로젝트 내부/외부 이해관계자 간의 원활한 의사소통을 위한 방법·절차 등 관리방안 수립
- 사업 초기 이해관계자를 식별하고 보고·검토계획 수립

#### 14.8.1 의사소통 관리 프로세스
| 단계 | 관리활동 | 세부 내용 |
|------|---------|----------|
| 프로젝트 착수 | 의사소통 채널 확보 및 체계 구축 | 프로젝트와 연관된 이해관계자 파악, 의사소통 채널 확보 |
| 프로젝트 계획 수립 | 의사소통 계획 수립 | 의사소통 채널에 맞는 담당자 역할 및 책임 정의, 내부/외부 이해관계자 간 의사소통 계획 수립 |
| 프로젝트 실행 및 통제 | 관계자 간 협조사항 관리 | 내/외부 이해관계자 간 업무보고 등 의사소통 활동, 의견조정 및 추적관리 |
| 프로젝트 종료 | 종료보고 및 수행 결과 정리 | 프로젝트의 공식적인 종료를 위해 고객 승인 획득, 승인 획득한 검수 확인서 사본을 고객사에 제출 |

### 14.9 인력 관리 (PMR-009)
- 인력 투입 및 철수 절차, 그에 따른 인수인계 절차 수립
- 투입인력 검증 방안 마련

#### 14.9.1 인력 투입 관리 방안
| 구분 | 수행 방안 |
|------|----------|
| 전문 인력의 효율적 투입 | 본 사업의 특성 및 다양한 분야의 프로젝트 관리 경험과 역량을 보유한 PM 투입, 사업 일정과 범위 분석에 따른 효율적 계획 수립 |
| 인력 변동의 최소화 | 사업 수행 중 핵심 인력이 유출되지 않도록 별도의 인사관리 실시하여 인력변동 최소화 |
| 인력 변동 리스크 제거 | 인력 변동 발생을 고려한 핵심인력 예비 Pool 유지, 변동 시 고객사 사전 보고 및 조정화 실시 |

#### 14.9.2 인력 교체 사유
1. **투입인력의 개인적 사유**: 퇴직, 병가, 임신, 사망 등 개인적인 사유로 불가피하게 교체가 필요한 경우
2. **아산병원의 요구**: 투입인력이 사업 수행에 있어 불성실하거나 수행능력이 미흡하다고 판단되어 교체 요구가 있는 경우

---

## 15. 보안 및 비상 대책 계획

### 15.1 보안 대책 (SER 상세)

#### 15.1.1 보안 관리 원칙
- 국가 정보보안 기본지침 및 병원 보안 정책에 의거한 보안관리 계획 수립
- 사업 수행에 있어 관련 지침과 법률에 따라 관리적/물리적/기술적 보안대책 수립

#### 15.1.2 접근 통제
| 분야 | 세부 항목 | 핵심관리 사항 |
|------|----------|-------------|
| 보안관리 계획 | 기술적 보안 | 보안 패치, 데이터 접근권한, 보안점검, 개인정보보호, 보안교육, 저장 매체, 출입통제, 반출·입 통제 |
| 보안관리 대상 | 관리적/물리적/기술적 보안 | 인증, 접근/권한통제, 암호화, 부인방지, 가용성/기타 |

#### 15.1.3 시스템 보안
| 정보시스템 계층 | Client | Network | Web Server | Application | DB |
|--------------|--------|---------|------------|-------------|-----|
| 인증 | 사용자 계정 생성, 단순 패스워드 제한/주기적 변경, 인증정보의 하드코딩 제한 |
| 접근/권한통제 | 주요정보시스템 접속제한, 인터넷 접속 제한, 개발/테스트/운영 망 분리, 관리자 역할 분리, 다중 연결 제한, DB 접근통제 |
| 암호화 | 문서 암호화, 전송구간 암호화, 사용자 인증 정보 암호화, DB 암호화, 표준 암호화 준수 |
| 부인방지 | 개인정보 출력 로깅, 조회 로깅, 주요정보 변경 로깅, 관리자/운영자 로깅, 시간 동기화, 자동 로그인 방지, DB 접근 로깅, 로깅정보 위/변조 방지 |

#### 15.1.4 개인정보보호 체계
- 개인정보보호 책임관 지정 및 전담 조직 구성
- 정보 취득부터 폐기까지 전 과정에 걸쳐 접근 제한
- 마스킹 처리 등 관리적·기술적 보안 조치 병행

| 구분 | 내용 |
|------|------|
| 취득 정보 관리 원칙 | 고객사의 승인을 득한 후 자료 확보, 업무 용도 이외 사용 금지, 제3자 제공 및 유출 금지, 용도 목적 달성 후 즉시 폐기·반납 |
| 관리적 조치사항 | 개인정보의 안전한 취급을 위한 관리체계 수립, 개인정보 관리책임자 지정, 개인정보의 안전한 보관을 위한 잠금 장치 등 물리적 접근 장치 조치 |
| 기술적 조치사항 | 개인정보에 접근 권한을 확인하기 위한 식별 및 인증 조치, 개인정보에 대한 권한 없는 접근 차단 위해 마스킹 처리 조치 |

### 15.2 비상 대책 (PMR-010)

#### 15.2.1 비상 대응 체계
| 조직 | 역할 |
|------|------|
| 비상대응본부장 (AI전략사업본부장) | 총괄 지휘 |
| 리스크관리팀 (사업관리 담당자) | 연관 부서 협조 대응, 대외협력 등 외부 커뮤니케이션 대응, 법률/노무 리스크 대응, 비상 연락망 관리 |
| 현장대응팀 (수행 PM) | 비상 상황별 대응 전략 및 실행 계획 수립, 비상 시 상황 투입 및 문제 해결 |
| 사후관리팀 (품질관리 담당자) | 비상 상황 실행계획 평가 및 개선점 도출, 훈련 및 시뮬레이션 진행, 복구 계획 마련 |

#### 15.2.2 비상 대응 방안
| 구분 | 판단기준 | 대응 방안 |
|------|---------|----------|
| 데이터 이행 오류 - 정합성 오류 | 오류 데이터의 범위, Cut-Over Plan 변경에 의한 재 이행 가능여부에 따라 결정 | 발생시점 판단 |
| 데이터 이행 오류 - 이행/검증 시간 초과 | Cut-Over Plan 변경에 의한 완료 가능 여부에 따라 결정 | 발생시점 판단 |
| 시스템 장애 - 일부 시스템 장애 | 운영에 지장 여부 판단, 문제발생 시 교체 용량 충실 등으로 해결 가능한 지 판단 | 해당 없음 |
| 시스템 장애 - 전체 시스템 장애 | 복구 예정 시간의 구 시스템 환원 시간 초과 여부에 의해 결정 | Fallback 높음 |
| 업무 수행 불가 - 일부 업무 불가 | 프로그램 오류, 데이터 오류로 장애 복구 시까지 수기관리로 해결 가능 | 해당 없음 |
| 업무 수행 불가 - 전 업무 불가 | 전체 시스템 장애로 발생, 복구 예정 시간의 구 시스템 환원 시간 초과 여부에 의해 결정 | Fallback |
| 원인 불명 | 원인 불명인 상태에서 지속시간에 따라 결정, 구 시스템 환원 소요 시간을 고려한 정시 가동 여부에 따라 결정 | Fallback 높음 |

#### 15.2.3 비상 대응 지원 방안
| 구분 | 지원 방법 |
|------|----------|
| 1단계 | 비상연락망 가동, 긴급정비 대기를 통한 신속 정확한 장애 조치 |
| 2단계 | 단계별 장애처리 절차 수립, 조직 구성, 정기/수시 점검을 통한 장애 예방 및 장애 발생 요인 제거 |
| 3단계 | 유지보수PM 자체 대응 가능한 경우, 장애 인지/신고 즉시 장애 대응 |

---

## 16. 기술 및 업무 이전 계획

### 16.1 기술이전 계획 (PSR-002 상세)

#### 16.1.1 기술이전 개요
- 운영 안정성과 실무 활용성을 모두 고려한 완성형 기술이전 지원
- 교육 중심 기술내재화, 단계별 병행 이행 전략, 기술문서 기반 운영 가이드 제공

#### 16.1.2 기술이전 항목 및 대상자
| 구분 | 기술이전 내용 | 기술이전 방안 | 시기 |
|------|------------|------------|------|
| 데이터 구조 및 모델 | 통합 데이터 플랫폼의 데이터 구조 개요, 논리 데이터 모델, 영역별 데이터 구성 개념, CDW/EDW/연구 데이터 영역 간 관계 및 활용 방식 | 데이터 구조 설명 자료 및 설계 산출물 제공, 주요 데이터 모델 예시 기반 설명 세션 진행 | 서비스 오픈 전/안정화 단계 |
| 데이터 수집·연계 및 적재 | 원천 시스템별 데이터 수집·연계 방식 개요, 배치/스트리밍 기반 데이터 적재 흐름 이해, 데이터 변환·적재(ETL/CDC) 처리 절차 및 관리 포인트 | 데이터 파이프라인 구성도 및 설명 자료 제공, 연계·적재 절차 중심 실무 교육 | 서비스 오픈 전/안정화 단계 |
| 메타데이터 및 데이터 품질 관리 | 데이터 품질 관리 기준 및 점검 항목, 메타데이터(기술/업무 메타) 관리 구조 이해, 데이터 카탈로그 활용 방식 및 관리 포인트 | 데이터 거버넌스 관련 매뉴얼 제공, 메타데이터 관리 솔루션 기능 실습 중심 교육, FAQ 및 운영 가이드 기반 설명 | 서비스 오픈 전/안정화 단계 |
| AI 기술 | AI Assistant 작동 원리 및 주요 기능 교육, AI 모델 활용법, 지능형 데이터 카탈로그 운영 로직 이해 | 사용자 매뉴얼 및 운영자 가이드 제공, 온·오프라인 병행 교육 진행, FAQ 및 시뮬레이션 기반 실습 | 서비스 오픈 전/안정화 단계 |
| 운영 및 모니터링 기술 | 사용자 권한 관리 및 보안 정책 적용, 로그/이력 관리 및 모니터링 방법, 성능·품질 모니터링 툴 사용법 | 운영자 대상 On-Site 교육, 표준 운영 절차(SOP) 문서화, 주기적 점검/리포트 체계 확립 | 안정화 단계 |
| 지속적 개선·고도화 | Prompt 및 대화 시나리오 개선 방법, 사용자 피드백 반영 프로세스, 신규 기능 추가/변경 반영 절차 | AI 운영 지원 인력 대상 교육, 업데이트 매뉴얼 제공, 정기 워크숍을 통한 개선안 공유 | 안정화 단계 |

#### 16.1.3 기술이전 절차
| 단계 | 활동 | 세부 내용 |
|------|------|----------|
| 01 대상 정의 및 이전범위 확정 | 사용자 역할별 기술이전 대상 식별, 이전 대상 기술 항목 매핑 | |
| 02 기술이전 계획 수립 | 기술이전 일정 및 방식 수립 (문서 또는 실습), 단계별 이행 시점 명확화 (구축 중 – 시범 운영 기간 – 정식 오픈 전) | |
| 03 문서 중심 사전 이전 | AI Agent 작동원리, 상담 활용 매뉴얼, 보안 준수 매뉴얼, 시스템 설정 및 구성값 문서화, 검토 요청 및 질의응답 진행 | 시스템 설계 문서, 기능별 설정 및 연계 문서, 운영 및 유지관리 매뉴얼, 보안 및 접근제어 문서, 사용자 교육/참고 문서 |
| 04 실습 기반 기술이전 수행 | 시나리오 기반 실습 세션 운영, 역할별 주요 기능 조작 실습, 고객 상담 시뮬레이션 실습, 자산관리 시나리오 기반 학습, Agent 응답 검증 훈련 | |
| 05 기술이전 결과 분석 | 자산관리 상담사 의견 수렴, 기술이전 보완 및 반복 교육 운영, Q&A 세션 및 On-Demand 대응 세션 제공 | |

#### 16.1.4 제공자료 목록
| 분류 | 자료 |
|------|------|
| 시스템 설계 문서 | 플랫폼 아키텍처 구성도, 데이터 흐름 설계서 |
| 기능별 설정 및 연계 문서 | 오픈소스 기반 연계 가이드, Prompt/시나리오 관리 문서 |
| 운영 및 유지관리 매뉴얼 | 운영자용 점검/모니터링 절차서, 배포 및 장애 대응 매뉴얼 |
| 보안 및 접근제어 문서 | 권한 관리 및 접근 정책 문서, 보안 설정 및 감사로그 관리 가이드 |
| 사용자 교육/참고 문서 | 역할별 요약 가이드북, FAQ 리스트 및 답변서, 직원용 활용 가이드 |

### 16.2 안정화 지원 (PSR-004 상세)

#### 16.2.1 안정화 지원 방안
- 안정적인 시스템 오픈 및 운영을 위해 시스템 구축에 참여한 전문 인력을 시스템 가동 이후 3개월 동안 상주하여 안정화 활동 수행/지원

#### 16.2.2 기술지원 체계
| 조직 | 역할 |
|------|------|
| 유지관리 및 하자담보팀 (기술지원팀) | 24시간 X 365일 기술지원, Knowledge Base Upgrade, 고객사별 담당자 배정단순 장애 처리, 원격 및 방문 지원 |
| Help Desk (품질테스트팀, 기술지원팀) | 메일 및 전화 접수 가능, 장애접수 및 기술문의 접수, 유지관리 및 하자담보 서비스 품질 확인 |
| 기술연구소 (TeraONE그룹, IRUDA그룹) | Bug Fix, Patch 제공, 체계적 Version Upgrade 수행 |

- **장애발생 시 업무시간 기준 4시간 이내에 시스템을 정상 가동시켜야 함**
- 납품한 제품에 대해 5년간 기술지원 제공

### 16.3 유지보수 계획 (PSR-001 상세)

#### 16.3.1 유지보수 관리 체계
- 유지보수 총괄을 중심으로 전담 기술PM, 기술부서, 솔루션/장비 공급사와 협업하여 유지보수 지원

#### 16.3.2 유지보수 조직 및 역할
| 조직 | 역할 |
|------|------|
| 유지보수 총괄 | 유지보수 계획 수립 및 일정 관리, 유지보수 조직 운영, 고객 커뮤니케이션 총괄, 위험요소 식별 및 대응, 상황전파 및 장애처리 결과분석 및 보고 |
| 기술지원 조직 | 기술지원 및 기술이전, 시스템 점검 및 성능 유지, 보안 조치 및 패치 대응 |
| 유지보수 전담 조직 | 사용자 지원팀 (플랫폼 이용 관련 사용자 문의 응대 및 이슈 대응, 사용자 피드백 수집 및 개선 요청 사항 정리·전달), 유지보수팀 (시스템 기능 오류, 버그 수정 및 패치 작업 수행, 모델/서비스 기능 개선 및 고도화 적용 지원), 시스템 관리팀 (플랫폼 인프라 모니터링 및 리소스 운영, 배포 환경 및 연계 모듈 상태 점검·복구 대응), 보안 관리팀 (접근 권한 및 감사 로그 관리, 데이터 보호 및 보안 정책 적용) |

#### 16.3.3 유지보수 절차
| 단계 | 활동 |
|------|------|
| Step 01 | 유지보수 계획 (일간/주간/월간 등) 수립 → 고객사 담당자 계획 승인 |
| Step 02 | 유지보수 활동 (예방점검, 장애처리 등) 계획수립 |
| Step 03 (장애 발생) | 장애 감지 → 장애분석 → 장애복구 수행 → 장애처리 완료 → 조치 결과 보고 |
| Step 03 (예방정비) | 정기/특별 점검 → 점검 승인 → 점검 활동 실행 → 예방점검 완료 → 점검결과 이력관리 |
| Step 03 (기술지원) | 기술지원 결과 확인 → 기술지원 결과 보고 |

#### 16.3.4 유지보수 능력 배양 계획
| 시기 | 교육 내용 | 대상 |
|------|----------|------|
| M+14 | 전체 매뉴얼 전달, 각 사용자별 실무 특성과 책임에 따라 차별화된 커리큘럼 제공 | 의료진, 플랫폼 운영 담당자, AI운영 지원 인력 |
| M+15 | 플랫폼 교육, 즉시 업무 적용이 가능하도록 Learn by Doing 기반 교육 실시 | |
| M+16 | 실습을 통한 이해, 시스템 도입-적용-운영/관리 관점에서 단계적으로 설계된 체계적인 교육 과정 운영 | |

---

**문서 끝**
