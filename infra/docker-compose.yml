services:
  # Milvus Vector Database (etcd + MinIO + Milvus)
  milvus-etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: milvus-etcd
    environment:
      ETCD_AUTO_COMPACTION_MODE: revision
      ETCD_AUTO_COMPACTION_RETENTION: "1000"
      ETCD_QUOTA_BACKEND_BYTES: "4294967296"
      ETCD_SNAPSHOT_COUNT: "50000"
    volumes:
      - ./data/milvus_etcd:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    restart: unless-stopped
    networks:
      - asan-network
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.50'

  minio:
    image: minio/minio:RELEASE.2024-01-01T16-36-33Z
    container_name: asan-minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    ports:
      - "19000:9000"
      - "19001:9001"
    volumes:
      - ./data/minio_data:/data
    command: minio server /data --console-address ":9001"
    restart: unless-stopped
    networks:
      - asan-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.50'

  milvus:
    image: milvusdb/milvus:v2.4.0
    container_name: milvus-standalone
    environment:
      ETCD_ENDPOINTS: milvus-etcd:2379
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
    ports:
      - "19530:19530"
      - "19091:9091"
    volumes:
      - ./data/milvus_data:/var/lib/milvus
    depends_on:
      milvus-etcd:
        condition: service_healthy
      minio:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - asan-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 20s
      retries: 5
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.00'

  # PostgreSQL for Airflow & MLflow
  postgres:
    image: postgres:16-alpine
    container_name: asan-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-asan}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-asan_db}
    ports:
      - "15432:5432"
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data
      - ../data_pipeline/scripts/init_db.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    networks:
      - asan-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.00'

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: asan-redis
    ports:
      - "16379:6379"
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 384mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    networks:
      - asan-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.50'

  # Apache Airflow (LocalExecutor)
  airflow-webserver:
    image: apache/airflow:2.8.1-python3.11
    container_name: asan-airflow-webserver
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER:-asan}:${POSTGRES_PASSWORD}@postgres:5432/airflow_db
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_ADMIN_USER:-admin}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
    ports:
      - "18080:8080"
    command: bash -c "airflow db migrate && airflow users create --username $${AIRFLOW_ADMIN_USER:-admin} --password $${AIRFLOW_ADMIN_PASSWORD:-admin} --firstname Admin --lastname User --role Admin --email admin@asan.com || true && airflow webserver"
    restart: unless-stopped
    networks:
      - asan-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.00'

  airflow-scheduler:
    image: apache/airflow:2.8.1-python3.11
    container_name: asan-airflow-scheduler
    depends_on:
      - postgres
      - redis
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER:-asan}:${POSTGRES_PASSWORD}@postgres:5432/airflow_db
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
    command: scheduler
    restart: unless-stopped
    networks:
      - asan-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.00'

  # MLflow Tracking Server
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.0
    container_name: asan-mlflow
    environment:
      MLFLOW_ARTIFACT_ROOT: /mlflow/artifacts
    ports:
      - "5000:5000"
    volumes:
      - ./data/mlflow_artifacts:/mlflow/artifacts
      - ./data/mlflow_db:/mlflow/db
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow/db/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    restart: unless-stopped
    networks:
      - asan-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.50'

  # JupyterLab for AI Analysis
  jupyterlab:
    image: quay.io/jupyter/datascience-notebook:python-3.11
    container_name: asan-jupyterlab
    user: root
    depends_on:
      - postgres
      - milvus
      - mlflow
    environment:
      JUPYTER_ENABLE_LAB: 'yes'
      GRANT_SUDO: 'yes'
      NB_UID: 1000
      NB_GID: 1000
      CHOWN_HOME: 'yes'
    ports:
      - "18888:8888"
    volumes:
      - ../notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
      - ../ai_services:/home/jovyan/ai_services
    command: start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''
    restart: unless-stopped
    networks:
      - asan-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.00'

  # Apache Superset for BI
  superset:
    image: apache/superset:3.1.0
    container_name: asan-superset
    depends_on:
      - postgres
      - redis
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY}
      SQLALCHEMY_DATABASE_URI: postgresql+psycopg2://${POSTGRES_USER:-asan}:${POSTGRES_PASSWORD}@postgres:5432/superset_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    ports:
      - "18088:8088"
    volumes:
      - ./data/superset_home:/app/superset_home
    command: >
      bash -c "superset db upgrade &&
               superset fab create-admin --username $${SUPERSET_ADMIN_USER:-admin} --firstname Admin --lastname User --email admin@asan.com --password $${SUPERSET_ADMIN_PASSWORD:-admin} || true &&
               superset init &&
               gunicorn --bind 0.0.0.0:8088 --workers 4 --timeout 120 'superset.app:create_app()'"
    restart: unless-stopped
    networks:
      - asan-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.00'

  # IDP API Server (FastAPI)
  api:
    build:
      context: ../data_portal/src/api
      dockerfile: Dockerfile
    container_name: asan-api
    depends_on:
      - postgres
      - redis
      - milvus
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-asan}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-asan_db}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      JWT_SECRET: ${JWT_SECRET}
      AUTH_REQUIRED: ${AUTH_REQUIRED:-true}
      MILVUS_HOST: milvus
      MILVUS_PORT: 19530
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      LLM_API_URL: ${LLM_API_URL:-http://host.docker.internal:8888/v1}
      LLM_MODEL: ${LLM_MODEL:-Qwen3-32B-AWQ}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      EMBEDDING_API_URL: ${EMBEDDING_API_URL:-http://host.docker.internal:8082}
    ports:
      - "8000:8000"
    restart: unless-stopped
    networks:
      - asan-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.00'

  # IDP Portal (사용자 웹 UI)
  portal:
    image: nginx:1.27-alpine
    container_name: asan-portal
    depends_on:
      - api
    ports:
      - "18000:80"
    volumes:
      - ../data_portal/src/portal/dist:/usr/share/nginx/html:ro
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    restart: unless-stopped
    networks:
      - asan-network
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # DuckDB OLAP Server - 추후 FastAPI 서버 구현 필요
  # duckdb-server:
  #   build:
  #     context: ./docker/duckdb
  #     dockerfile: Dockerfile
  #   container_name: asan-duckdb
  #   ports:
  #     - "8089:8089"
  #   volumes:
  #     - ./data/duckdb:/data
  #     - ./src/olap:/app/olap
  #   restart: unless-stopped
  #   networks:
  #     - asan-network

  # XiYanSQL-QwenCoder-7B vLLM Serving
  xiyan-sql-vllm:
    image: vllm/vllm-openai:v0.6.6.post1
    container_name: asan-xiyan-sql
    environment:
      NVIDIA_VISIBLE_DEVICES: "0"
      HF_HOME: /root/.cache/huggingface
    volumes:
      - /home/babelai/.cache/huggingface:/root/.cache/huggingface:ro
    ports:
      - "8001:8000"
    command:
      - "--model"
      - "XGenerationLab/XiYanSQL-QwenCoder-7B-2504"
      - "--served-model-name"
      - "XiYanSQL-QwenCoder-7B-2504"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "8000"
      - "--dtype"
      - "bfloat16"
      - "--max-model-len"
      - "4096"
      - "--gpu-memory-utilization"
      - "0.85"
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '2.00'
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - asan-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s

networks:
  asan-network:
    driver: bridge

volumes:
  postgres_data:
  milvus_data:
  milvus_etcd:
  minio_data:
  mlflow_artifacts:
  superset_home:
